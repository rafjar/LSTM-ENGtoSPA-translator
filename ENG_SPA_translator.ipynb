{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpcBikB1UdU0u4K0uoeSZf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80e5a46ea533450db19256ae65cf3168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c32d7f13558414dbaaca5b7831d5ac5",
              "IPY_MODEL_1b33e7af98fa4f68a489ca13be1a390c",
              "IPY_MODEL_f4671973dad24139a24898bc502647ba"
            ],
            "layout": "IPY_MODEL_00fc7c3343b840fda91fef678b1a0f3b"
          }
        },
        "8c32d7f13558414dbaaca5b7831d5ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d3dcce87f6e46c0956454390e53e55a",
            "placeholder": "​",
            "style": "IPY_MODEL_507262477447455aa13ce42168649379",
            "value": "Epoch 9: 100%"
          }
        },
        "1b33e7af98fa4f68a489ca13be1a390c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c90752571394a92822082252c7b995e",
            "max": 3125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c898db6859e4d5fb05952539c9d1786",
            "value": 3125
          }
        },
        "f4671973dad24139a24898bc502647ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfdc6abd02bc4b4fb1e74fef3b29b8f5",
            "placeholder": "​",
            "style": "IPY_MODEL_713952b250c24d25a91daa2e2d7b6b2c",
            "value": " 3125/3125 [00:46&lt;00:00, 67.49it/s, v_num=2, train_loss_step=0.222, train_loss_epoch=0.171]"
          }
        },
        "00fc7c3343b840fda91fef678b1a0f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8d3dcce87f6e46c0956454390e53e55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "507262477447455aa13ce42168649379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c90752571394a92822082252c7b995e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c898db6859e4d5fb05952539c9d1786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfdc6abd02bc4b4fb1e74fef3b29b8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713952b250c24d25a91daa2e2d7b6b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "POTK9IAVpc38"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdxmw6lOQOaz",
        "outputId": "9e5c31ca-2c01-4f64-be46-208fba3ba996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-29 10:13:18--  https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 2607:f8b0:4023:c0d::cf, 2607:f8b0:4023:c03::cf, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2638744 (2.5M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip         100%[===================>]   2.52M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-11-29 10:13:18 (182 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\n",
            "\n",
            "Archive:  spa-eng.zip\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.7.22)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.23.5)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (23.2)\n",
            "Requirement already satisfied: torch<4.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.2.0)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.5.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning) (2.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip -O spa-eng.zip\n",
        "!unzip -u spa-eng.zip\n",
        "!pip install tokenizers\n",
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers import normalizers\n",
        "from tokenizers import pre_tokenizers\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import lightning as L\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "Z4-7WHZxpia5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "XkwzP0taRNYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('spa-eng/spa.txt', sep='\\t', header=None).sample(frac=1)\n",
        "text_en, text_es = raw_data[0].values, raw_data[1].values\n",
        "\n",
        "for i in range(3):\n",
        "    print(f'{text_en[i]} ==> {text_es[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LIB6mlkQgvu",
        "outputId": "0a92aeb6-6803-4cb3-8f70-b6c6f6c8cd39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She divided the cake into five pieces. ==> Ella dividió la torta en cinco porciones.\n",
            "I must be true to myself. ==> Debo ser honesto conmigo mismo.\n",
            "Black cats are bad luck. ==> Los gatos negros traen mala suerte.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000\n",
        "\n",
        "tokenizer_en = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "\n",
        "normalizer = normalizers.Sequence([normalizers.NFKC(), normalizers.Lowercase()])\n",
        "tokenizer_en.normalizer = normalizer\n",
        "\n",
        "pre_tokenizer = pre_tokenizers.Sequence([pre_tokenizers.Punctuation(), pre_tokenizers.Whitespace()])\n",
        "tokenizer_en.pre_tokenizer = pre_tokenizer\n",
        "\n",
        "trainer_en = WordLevelTrainer(vocab_size=vocab_size, show_progress=True, special_tokens=['[PAD]', '[UNK]'])\n",
        "\n",
        "tokenizer_en.train_from_iterator(text_en, trainer_en)"
      ],
      "metadata": {
        "id": "GV9jUDm8QuNe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_es = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "\n",
        "normalizer = normalizers.Sequence([normalizers.NFKC(), normalizers.Lowercase()])\n",
        "tokenizer_es.normalizer = normalizer\n",
        "\n",
        "pre_tokenizer = pre_tokenizers.Sequence([pre_tokenizers.Punctuation(), pre_tokenizers.Whitespace()])\n",
        "tokenizer_es.pre_tokenizer = pre_tokenizer\n",
        "\n",
        "trainer_es = WordLevelTrainer(vocab_size=vocab_size, show_progress=True, special_tokens=['[PAD]', '[UNK]', '[BOS]', '[EOS]'])\n",
        "\n",
        "tokenizer_es.train_from_iterator(text_es, trainer_es)\n",
        "\n",
        "tokenizer_es_x = Tokenizer.from_str(tokenizer_es.to_str())\n",
        "tokenizer_es_y = Tokenizer.from_str(tokenizer_es.to_str())\n",
        "\n",
        "tokenizer_es_x.post_processor = TemplateProcessing(\n",
        "    single='[BOS] $A',\n",
        "    special_tokens=[('[BOS]', 2)]\n",
        ")\n",
        "tokenizer_es_y.post_processor = TemplateProcessing(\n",
        "    single='$A [EOS]',\n",
        "    special_tokens=[('[EOS]', 3)]\n",
        ")"
      ],
      "metadata": {
        "id": "BeqC6Zq1gQN2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_en = tokenizer_en.encode_batch(text_en)\n",
        "tokenized_en = [torch.tensor(i.ids) for i in tokenized_en]\n",
        "tokenized_es_x = tokenizer_es_x.encode_batch(text_es)\n",
        "tokenized_es_x = [torch.tensor(i.ids) for i in tokenized_es_x]\n",
        "tokenized_es_y = tokenizer_es_y.encode_batch(text_es)\n",
        "tokenized_es_y = [torch.tensor(i.ids) for i in tokenized_es_y]"
      ],
      "metadata": {
        "id": "2E95W7_GiaL3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataset and dataloader"
      ],
      "metadata": {
        "id": "r2e3ZUnMqa1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnglishSpanishDataset(Dataset):\n",
        "    def __init__(self, tokenized_en, tokenized_es_x, tokenized_es_y):\n",
        "        self.tokenized_en = nn.utils.rnn.pad_sequence(tokenized_en, batch_first=True)\n",
        "        self.tokenized_es_x = nn.utils.rnn.pad_sequence(tokenized_es_x, batch_first=True)\n",
        "        self.tokenized_es_y = nn.utils.rnn.pad_sequence(tokenized_es_y, batch_first=True)\n",
        "\n",
        "        self.seq_len_en = [len(i) for i in tokenized_en]\n",
        "        self.seq_len_es = [len(i) for i in tokenized_es_x]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_en)\n",
        "\n",
        "    def __getitem__(self, indx):\n",
        "        (x_enc, x_enc_len) = (self.tokenized_en[indx], self.seq_len_en[indx])\n",
        "        (x_dec, x_dec_len) = (self.tokenized_es_x[indx], self.seq_len_es[indx])\n",
        "        y_dec = self.tokenized_es_y[indx]\n",
        "        return (x_enc, x_enc_len), (x_dec, x_dec_len), y_dec"
      ],
      "metadata": {
        "id": "ifptDqKVqyq6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_en, train_es_x, train_es_y = tokenized_en[:100_000], tokenized_es_x[:100_000], tokenized_es_y[:100_000]\n",
        "valid_en, valid_es_x, valid_es_y = tokenized_en[100_000:], tokenized_es_x[100_000:], tokenized_es_y[100_000:]\n",
        "\n",
        "train_dataset = EnglishSpanishDataset(train_en, train_es_x, train_es_y)\n",
        "valid_dataset = EnglishSpanishDataset(valid_en, valid_es_x, valid_es_y)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "MF5KI22RwPHp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "AyfxDpyCpBgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(L.LightningModule):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embed_dim, hidden_size)\n",
        "\n",
        "    def forward(self, input, seq_lenghts):\n",
        "        x = self.embed(input).swapaxes(0, 1)\n",
        "        x = nn.utils.rnn.pack_padded_sequence(x, lengths=seq_lenghts.to('cpu'), enforce_sorted=False)\n",
        "        _, state = self.rnn(x)\n",
        "\n",
        "        return state"
      ],
      "metadata": {
        "id": "uGV0LpR9pt_w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(L.LightningModule):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embed_dim, hidden_size)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input, init_state, seq_lenghts):\n",
        "        x = self.embed(input).swapaxes(0, 1)\n",
        "        x = nn.utils.rnn.pack_padded_sequence(x, lengths=seq_lenghts.to('cpu'), enforce_sorted=False)\n",
        "        x, (h_n, c_n) = self.rnn(x, init_state)\n",
        "        x, x_seq_lengths = nn.utils.rnn.pad_packed_sequence(x)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x#, (h_n, c_n)"
      ],
      "metadata": {
        "id": "Vj-nHjVFQ2K2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(L.LightningModule):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc = Encoder(vocab_size, embed_dim, hidden_size)\n",
        "        self.dec = Decoder(vocab_size, embed_dim, hidden_size)\n",
        "\n",
        "    def training_step(self, batch, batch_indx):\n",
        "        (x_enc, x_enc_len), (x_dec, x_dec_len), y_dec = batch\n",
        "\n",
        "        init_state = self.enc(x_enc, x_enc_len)\n",
        "        output = self.dec(x_dec, init_state, x_dec_len)\n",
        "        output = output.swapaxes(0, 1).swapaxes(1, 2)\n",
        "        y_dec = y_dec[:,:output.shape[-1]]\n",
        "\n",
        "        loss = F.cross_entropy(output, y_dec)\n",
        "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=0.001)\n",
        "\n",
        "    def translate_sentence(self, sentence_en, max_seq_size=60, tokenizer_en=tokenizer_en, tokenizer_es=tokenizer_es):\n",
        "\n",
        "        tokenized_en = tokenizer_en.encode_batch([sentence_en])\n",
        "        tokenized_en = torch.tensor([i.ids for i in tokenized_en])\n",
        "        seq_len_en = torch.tensor([len(tokenized_en[0])])\n",
        "\n",
        "        init_state = self.enc(tokenized_en, seq_len_en) # init state from encoder\n",
        "        translated_tokens = [tokenizer_es.get_vocab()['[BOS]']] # Tokens starting with [BOS]\n",
        "\n",
        "        for i in range(max_seq_size):\n",
        "            output = self.dec(torch.tensor([translated_tokens]), init_state, torch.tensor([i+1]))\n",
        "            new_word = output[i,0].topk(1).indices.item()\n",
        "            translated_tokens.append(new_word)\n",
        "            if new_word == tokenizer_es.token_to_id('[EOS]'):\n",
        "                break\n",
        "\n",
        "        return tokenizer_es.decode(translated_tokens)\n",
        "\n",
        "t = Translator(vocab_size=vocab_size, embed_dim=128, hidden_size=512)"
      ],
      "metadata": {
        "id": "-Z2fDM5VTY8U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = Translator(vocab_size=vocab_size, embed_dim=128, hidden_size=512)\n",
        "trainer = L.Trainer(max_epochs=10)\n",
        "trainer.fit(model=t, train_dataloaders=train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605,
          "referenced_widgets": [
            "80e5a46ea533450db19256ae65cf3168",
            "8c32d7f13558414dbaaca5b7831d5ac5",
            "1b33e7af98fa4f68a489ca13be1a390c",
            "f4671973dad24139a24898bc502647ba",
            "00fc7c3343b840fda91fef678b1a0f3b",
            "8d3dcce87f6e46c0956454390e53e55a",
            "507262477447455aa13ce42168649379",
            "7c90752571394a92822082252c7b995e",
            "5c898db6859e4d5fb05952539c9d1786",
            "dfdc6abd02bc4b4fb1e74fef3b29b8f5",
            "713952b250c24d25a91daa2e2d7b6b2c"
          ]
        },
        "id": "eNJ7akU2QsJX",
        "outputId": "f73b382b-e003-4dac-fd77-c0a6ff97d4b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: IPU available: False, using: 0 IPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name | Type    | Params\n",
            "---------------------------------\n",
            "0 | enc  | Encoder | 1.4 M \n",
            "1 | dec  | Decoder | 2.0 M \n",
            "---------------------------------\n",
            "3.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.4 M     Total params\n",
            "13.595    Total estimated model params size (MB)\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name | Type    | Params\n",
            "---------------------------------\n",
            "0 | enc  | Encoder | 1.4 M \n",
            "1 | dec  | Decoder | 2.0 M \n",
            "---------------------------------\n",
            "3.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.4 M     Total params\n",
            "13.595    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80e5a46ea533450db19256ae65cf3168"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.translate_sentence('I like soccer!'))\n",
        "print(t.translate_sentence('Hello, how are you?'))\n",
        "print(t.translate_sentence('Have a nice day.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFf4D0vH1EP2",
        "outputId": "bfffd0b2-13e2-40e8-935b-08aa3753f716"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡ me gusta el fútbol !\n",
            "¿ a qué tal estás ?\n",
            "un buen día .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8D-qQ5qwmpQ"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}